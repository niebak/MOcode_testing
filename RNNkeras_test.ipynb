{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN example found on the tensorflow/keras website\n",
    "Testing to learn how to use RNNs.\n",
    "On my computer this requires the \"tf\" environment. \n",
    "The tf environment can most likely be found by activating it, but if not it is also available through the anaconda navigator.\n",
    "Website: https://www.tensorflow.org/guide/keras/rnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, None, 64)          64000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               98816     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model =  keras.Sequential()\n",
    "\n",
    "# Add a embedding layer with input 1k and output 600\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add LSTM with 128 internal units, and a dense layer with 10 units\n",
    "model.add(layers.LSTM(128))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model defined here starts by embedding the input into a 64-dimensional vector, and then uses 128 LSTM cells before passing it to a dense layer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating another model\n",
    "This model uses Gated Recurrent units(GRUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, None, 64)          64000     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, None, 256)         247296    \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 128)               49280     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361,866\n",
      "Trainable params: 361,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000,output_dim=64))\n",
    "# Add  GRU, RNN, and dense layers\n",
    "model.add(layers.GRU(256,return_sequences=True))\n",
    "model.add(layers.SimpleRNN(128))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# Show the model\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A third model, and a new method of creating it\n",
    "This model also utilizes the internal state of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, None, 64)     64000       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)       (None, None, 64)     128000      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " encoder (LSTM)                 [(None, 64),         33024       ['embedding_9[0][0]']            \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " decoder (LSTM)                 (None, 64)           33024       ['embedding_10[0][0]',           \n",
      "                                                                  'encoder[0][1]',                \n",
      "                                                                  'encoder[0][2]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 10)           650         ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 258,698\n",
      "Trainable params: 258,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "e_vocab=10**3\n",
    "d_vocab=2*10**3\n",
    "\n",
    "encoder_input=layers.Input(shape=(None,))\n",
    "encoder_embedded = layers.Embedding(input_dim=e_vocab,output_dim=64)(encoder_input)\n",
    "\n",
    "# Return states in addition to the output\n",
    "output, state_h,state_c = layers.LSTM(64,return_state=True,name=\"encoder\")(encoder_embedded)\n",
    "encoder_state=[state_h,state_c]\n",
    "\n",
    "# Setup the decoder\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedded = layers.Embedding(input_dim=d_vocab, output_dim=64)(decoder_input)\n",
    "\n",
    "decoder_output = layers.LSTM(64,name=\"decoder\")(decoder_embedded, initial_state=encoder_state)\n",
    "output = layers.Dense(10)(decoder_output)\n",
    "model = keras.Model([encoder_input,decoder_input],output)\n",
    "model.summary()\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db177db2950e08f5047112e7e8400b5311c79c0035d760e3eef28fe52159a1cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
